<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xml:lang=
"en-US">
<head>
<title>Chapter 14: Providing Sampled-Audio Services</title>
<link rel="stylesheet" type="text/css" href="../../../../technotes/css/guide.css" />
</head>
<body>
<!-- STATIC HEADER -->

<!-- header start -->
<div id="javaseheader">
<div id="javaseheaderlogo">
<img src="../../../../images/javalogo.gif"
alt="Java logo" />
</div>
<div id="javaseheaderindex">

<a href=
"../../../../index.html">Documentation Contents</a>
</div>
<div class="clear"></div>
</div>

<!-- header end -->


<p><small><a href="contents.html">&lt; Contents</a></small></p>
<h1>Chapter 14: Providing Sampled-Audio Services</h1>
<p><a name="a118162" id="a118162"></a> As discussed in Chapter 13,
"<a href="chapter13.html">Introduction to the Service Provider
Interfaces</a>," the Java Sound API includes two packages,
<code>javax.sound.sampled.spi</code> and
<code>javax.sound.midi.spi</code>, that define abstract classes to
be used by developers of sound services. By implementing and
installing a subclass of one of these abstract classes, a service
provider registers the new service, extending the functionality of
the runtime system. The present chapter tells you how to go about
using the <code>javax.sound.sampled.spi</code> package to provide
new services for handling sampled audio.</p>
<p><a name="a119684" id="a119684"></a> This chapter can be safely
skipped by application programmers who merely wish to use existing
audio services in their programs. For the use of the installed
audio services in an application program, see Part I, "Sampled
Audio," of this Programmer's Guide. This chapter assumes that the
reader is familiar with the Java Sound API methods that application
programs invoke to access installed audio services.</p>
<a name="a118164" id="a118164"></a>
<h2>Introduction</h2>
<p><a name="a118166" id="a118166"></a> There are four abstract
classes in the <code>javax.sound.sampled.spi</code> package,
representing four different types of services that you can provide
for the sampled-audio system:</p>
<ul>
<li style="list-style: none"><a name="a118167" id=
"a118167"></a></li>
<li><code>AudioFileWriter</code> provides sound file-writing
services. These services make it possible for an application
program to write a stream of audio data to a file of a particular
type. <a name="a118168" id="a118168"></a></li>
<li><code>AudioFileReader</code> provides file-reading services.
These services enable an application program to ascertain a sound
file's characteristics, and to obtain a stream from which the
file's audio data can be read. <a name="a118169" id=
"a118169"></a></li>
<li><code>FormatConversionProvider</code> provides services for
converting audio data formats. These services allow an application
program to translate audio streams from one data format to another.
<a name="a118170" id="a118170"></a></li>
<li><code>MixerProvider</code> provides management of a particular
kind of mixer. This mechanism allows an application program to
obtain information about, and access instances of, a given kind of
mixer.
<p><a name="a118172" id="a118172"></a></p>
</li>
</ul>
To recapitulate the discussion in Chapter 13, service providers can
extend the functionality of the runtime system. A typical SPI class
has two types of methods: ones that respond to queries about the
types of services available from a particular provider, and ones
that either perform the new service directly, or return instances
of objects that actually provide the service. The runtime
environment's service-provider mechanism provides
<em>registration</em> of installed services with the audio system,
and <em>management</em> of the new service provider classes.
<p><a name="a120967" id="a120967"></a> In essence there is a double
isolation of the service instances from the application developer.
An application program never directly creates instances of the
service objects, such as mixers or format converters, that it needs
for its audio processing tasks. Nor does the program even directly
request these objects from the SPI classes that administer them.
The application program makes requests to the
<code>AudioSystem</code> object in the
<code>javax.sound.sampled</code> package, and
<code>AudioSystem</code> in turn uses the SPI objects to process
these queries and service requests.</p>
<p><a name="a120968" id="a120968"></a> The existence of new audio
services might be completely transparent to both the user and the
application programmer. All application references are through
standard objects of the <code>javax.sound.sampled</code> package,
primarily <code>AudioSystem</code>, and the special handling that
new services might be providing is often completely hidden.</p>
<p><a name="a120974" id="a120974"></a> In this chapter, we'll
continue the previous chapter's convention of referring to new SPI
subclasses by names like <code>AcmeMixer</code> and
<code>AcmeMixerProvider</code>.</p>
<a name="a118177" id="a118177"></a>
<h2>Providing Audio File-Writing Services</h2>
<p><a name="a118179" id="a118179"></a> Let's start with
<code>AudioFileWriter</code>, one of the simpler SPI classes.</p>
<p><a name="a119866" id="a119866"></a> A subclass that implements
the methods of <code>AudioFileWriter</code> must provide
implementations of a set of methods to handle queries about the
file formats and file types supported by the class, as well as
provide methods that actually write out a supplied audio data
stream to a <code>File</code> or <code>OutputStream</code>.</p>
<p><a name="a119867" id="a119867"></a> <code>AudioFileWriter</code>
includes two methods that have concrete implementations in the base
class:</p>
<pre>
boolean isFileTypeSupported(AudioFileFormat.Type fileType) 
boolean isFileTypeSupported(AudioFileFormat.Type fileType, 
    AudioInputStream stream) 
</pre>
The first of these methods informs the caller whether this file
writer can write sound files of the specified type. This method is
a general inquiry, it will return <code>true</code> if the file
writer can write that kind of file, assuming the file writer is
handed appropriate audio data. However, the ability to write a file
can depend on the format of the specific audio data that's handed
to the file writer. A file writer might not support every audio
data format, or the constraint might be imposed by the file format
itself. (Not all kinds of audio data can be written to all kinds of
sound files.) The second method is more specific, then, asking
whether a particular <code>AudioInputStream</code> can be written
to a particular type of file.
<p><a name="a119891" id="a119891"></a> Generally, you won't need to
override these two concrete methods. Each is simply a wrapper that
invokes one of two other query methods and iterates over the
results returned. These other two query methods are abstract and
therefore need to be implemented in the subclass:</p>
<pre>
abstract AudioFileFormat.Type[] getAudioFileTypes() 
abstract AudioFileFormat.Type[]
    getAudioFileTypes(AudioInputStream stream) 
</pre>
These methods correspond directly to the previous two. Each returns
an array of all the supported file types-all that are supported in
general, in the case of the first method, and all that are
supported for a specific audio stream, in the case of the second
method. A typical implementation of the first method might simply
return an array that the file writer's constructor initializes. An
implementation of the second method might test the stream's
<code>AudioFormat</code> object to see whether it's a data format
that the requested type of file supports.
<p><a name="a119946" id="a119946"></a> The final two methods of
<code>AudioFileWriter</code> do the actual file-writing work:</p>
<pre>
abstract  int write(AudioInputStream stream, 
    AudioFileFormat.Type fileType, java.io.File out) 
 abstract  int write(AudioInputStream stream, 
    AudioFileFormat.Type fileType, java.io.OutputStream out) 
</pre>
These methods write a stream of bytes representing the audio data
to the stream or file specified by the third argument. The details
of how this is done depend on the structure of the specified type
of file. The <code>write</code> method must write the file's header
and the audio data in the manner prescribed for sound files of this
format (whether it's a standard type of sound file or a new,
possibly proprietary one). <a name="a118201" id="a118201"></a>
<h2>Providing Audio File-Reading Services</h2>
<p><a name="a120146" id="a120146"></a> The
<code>AudioFileReader</code> class consists of six abstract methods
that your subclass needs to implement-actually, two different
overloaded methods, each of which can take a <code>File</code>,
<code>URL</code>, or <code>InputStream</code> argument. The first
of these overloaded methods accepts queries about the file format
of a specified file:</p>
<pre>
abstract AudioFileFormat getAudioFileFormat(
    java.io.File file) 
abstract AudioFileFormat getAudioFileFormat(
    java.io.InputStream stream) 
abstract AudioFileFormat getAudioFileFormat(
    java.net.URL url) 
</pre>
A typical implementation of <code>getAudioFileFormat</code> method
reads and parses the sound file's header to ascertain its file
format. See the description of the AudioFileFormat class to see
what fields need to be read from the header, and refer to the
specification for the particular file type to figure out how to
parse the header.
<p><a name="a120204" id="a120204"></a> Because the caller providing
a stream as an argument to this method expects the stream to be
unaltered by the method, the file reader should generally start by
marking the stream. After reading to the end of the header, it
should reset the stream to its original position.</p>
<p><a name="a120135" id="a120135"></a> The other overloaded
<code>AudioFileReader</code> method provides file-reading services,
by returning an AudioInputStream from which the file's audio data
can be read:</p>
<pre>
abstract AudioInputStream getAudioInputStream(
    java.io.File file) 
abstract AudioInputStream getAudioInputStream(
     java.io.InputStream stream) 
abstract AudioInputStream getAudioInputStream(
     java.net.URL url) 
</pre>
Typically, an implementation of <code>getAudioInputStream</code>
returns an <code>AudioInputStream</code> wound to the beginning of
the file's data chunk (after the header), ready for reading. It
would be conceivable, though, for a file reader to return an
<code>AudioInputStream</code> whose audio format represents a
stream of data that is in some way decoded from what is contained
in the file. The important thing is that the method return a
formatted stream from which the audio data contained in the file
can be read. The <code>AudioFormat</code> encapsulated in the
returned <code>AudioInputStream</code> object will inform the
caller about the stream's data format, which is usually, but not
necessarily, the same as the data format in the file itself.
<p><a name="a120248" id="a120248"></a> Generally, the returned
stream is an instance of <code>AudioInputStream</code>; it's
unlikely you would ever need to subclass
<code>AudioInputStream</code>.</p>
<a name="a118208" id="a118208"></a>
<h2>Providing Format-Conversion Services</h2>
<p><a name="a120439" id="a120439"></a> A
<code>FormatConversionProvider</code> subclass transforms an
<code>AudioInputStream</code> that has one audio data format into
one that has another format. The former (input) stream is referred
to as the <em>source</em> stream, and the latter (output) stream is
referred to as the <em>target</em> stream. Recall from Chapter 2,
"Overview of the Sampled Package," that an
<code>AudioInputStream</code> contains an <code>AudioFormat</code>,
and the <code>AudioFormat</code> in turn contains a particular type
of data encoding, represented by an
<code>AudioFormat.Encoding</code> object. The format and encoding
in the source stream are called the source format and source
encoding, and those in the target stream are likewise called the
target format and target encoding.</p>
<p><a name="a120267" id="a120267"></a> The work of conversion is
performed in the overloaded abstract method of
<code>FormatConversionProvider</code> called
<code>getAudioInputStream</code>. The class also has abstract query
methods for learning about all the supported target and source
formats and encodings. There are concrete wrapper methods for
querying about a specific conversion.</p>
<p><a name="a120265" id="a120265"></a> The two variants of
<code>getAudioInputStream</code> are:</p>
<pre>
abstract AudioInputStream getAudioInputStream(
    AudioFormat.Encoding targetEncoding, 
    AudioInputStream sourceStream) 
        
</pre>
and
<pre>
abstract AudioInputStream getAudioInputStream(
    AudioFormat targetFormat,
    AudioInputStream sourceStream) 
</pre>
These differ in the first argument, according to whether the caller
is specifying a complete target format or just the format's
encoding.
<p><a name="a120460" id="a120460"></a> A typical implementation of
<code>getAudioInputStream</code> works by returning a new subclass
of <code>AudioInputStream</code> that wraps around the original
(source) <code>AudioInputStream</code> and applies a data format
conversion to its data whenever a <code>read</code> method is
invoked. For example, consider the case of a new
<code>FormatConversionProvider</code> subclass called
<code>AcmeCodec</code>, which works with a new
<code>AudioInputStream</code> subclass called
<code>AcmeCodecStream</code>.</p>
<p><a name="a118212" id="a118212"></a> The implementation of
<code>AcmeCodec's</code> second <code>getAudioInputStream</code>
method might be:</p>
<pre>
public AudioInputStream getAudioInputStream
      (AudioFormat outputFormat, AudioInputStream stream) {
        AudioInputStream cs = null;
        AudioFormat inputFormat = stream.getFormat();
        if (inputFormat.matches(outputFormat) ) {
            cs = stream;
        } else {
            cs = (AudioInputStream)
                (new AcmeCodecStream(stream, outputFormat));
            tempBuffer = new byte[tempBufferSize];
        }
        return cs;
    }
</pre>
The actual format conversion takes place in new <code>read</code>
methods of the returned <code>AcmeCodecStream</code>, a subclass of
<code>AudioInputStream</code>. Again, application programs that
access this returned <code>AcmeCodecStream</code> simply operate on
it as an <code>AudioInputStream</code>, and don't need to know the
details of its implementation.
<p><a name="a118232" id="a118232"></a> The other methods of a
<code>FormatConversionProvider</code> all permit queries about the
input and output encodings and formats that the object supports.
The following four methods, being abstract, need to be
implemented:</p>
<pre>
abstract AudioFormat.Encoding[] getSourceEncodings() 
abstract AudioFormat.Encoding[] getTargetEncodings() 
abstract AudioFormat.Encoding[] getTargetEncodings(
    AudioFormat sourceFormat) 
abstract  AudioFormat[] getTargetFormats(
    AudioFormat.Encoding targetEncoding, 
    AudioFormat sourceFormat) 
</pre>
<p>As in the query methods of the <code>AudioFileReader</code>
class discussed above, these queries are typically handled by
checking private data of the object and, for the latter two
methods, comparing them against the argument(s).</p>
<p><a name="a120475" id="a120475"></a> The remaining four
<code>FormatConversionProvider</code> methods are concrete and
generally don't need to be overridden:</p>
<pre>
boolean isConversionSupported(
    AudioFormat.Encoding targetEncoding,
    AudioFormat sourceFormat) 
boolean isConversionSupported(AudioFormat targetFormat, 
    AudioFormat sourceFormat) 
boolean isSourceEncodingSupported(
    AudioFormat.Encoding sourceEncoding) 
boolean isTargetEncodingSupported(
    AudioFormat.Encoding targetEncoding) 
</pre>
As with <code>AudioFileWriter.isFileTypeSupported()</code>, the
default implementation of each of these methods is essentially a
wrapper that invokes one of the other query methods and iterates
over the results returned. <a name="a120618" id="a120618"></a>
<h2>Providing New Types of Mixers</h2>
<p><a name="a118235" id="a118235"></a> As its name implies, a
<code>MixerProvider</code> supplies instances of mixers. Each
concrete <code>MixerProvider</code> subclass acts as a factory for
the <code>Mixer</code> objects used by an application program. Of
course, defining a new <code>MixerProvider</code> only makes sense
if one or more new implementations of the <code>Mixer</code>
interface are also defined. As in the
<code>FormatConversionProvider</code> example above, where our
<code>getAudioInputStream</code> method returned a subclass of
<code>AudioInputStream</code> that performed the conversion, our
new class <code>AcmeMixerProvider</code> has a method
<code>getMixer</code> that returns an instance of another new class
that implements the <code>Mixer</code> interface. We'll call the
latter class <code>AcmeMixer</code>. Particularly if the mixer is
implemented in hardware, the provider might support only one static
instance of the requested device. If so, it should return this
static instance in response to each invocation of
<code>getMixer</code>.</p>
<p><a name="a118238" id="a118238"></a> Since <code>AcmeMixer</code>
supports the <code>Mixer</code> interface, application programs
don't require any additional information to access its basic
functionality. However, if <code>AcmeMixer</code> supports
functionality not defined in the <code>Mixer</code> interface, and
the vendor wants to make this extended functionality accessible to
application programs, the mixer should of course be defined as a
public class with additional, well-documented public methods, so
that a program that wishes to make use of this extended
functionality can import <code>AcmeMixer</code> and cast the object
returned by <code>getMixer</code> to this type.</p>
<p><a name="a120792" id="a120792"></a> The other two methods of
<code>MixerProvider</code> are:</p>
<pre>
abstract Mixer.Info[] getMixerInfo() 
</pre>
and
<pre>
boolean isMixerSupported(Mixer.Info info) 
</pre>
These methods allow the audio system to determine whether this
particular provider class can produce a device that an application
program needs. In other words, the <code>AudioSystem</code> object
can iterate over all the installed <code>MixerProviders</code> to
see which ones, if any, can supply the device that the application
program has requested of the <code>AudioSystem</code>. (See the
discussion under "<a href="chapter3.html#a113128">Getting a
Mixer</a>" in Chapter 3, "<a href="chapter3.html">Accessing Audio
System Resources</a>.") The <code>getMixerInfo</code> method
returns an array of objects containing information about the kinds
of mixer available from this provider object. The system can pass
these information objects, along with those from other providers,
to an application program.
<p><a name="a120729" id="a120729"></a> A single
<code>MixerProvider</code> can provide more than one kind of mixer.
When the system invokes the <code>MixerProvider's
getMixerInfo</code> method, it gets a list of information objects
identifying the different kinds of mixer that this provider
supports. The system can then invoke
<code>MixerProvider.getMixer(Mixer.Info)</code> to obtain each
mixer of interest.</p>
<p><a name="a120841" id="a120841"></a> Your subclass needs to
implement <code>getMixerInfo</code>, as it's abstract. The
<code>isMixerSupported</code> method is concrete and doesn't
generally need to be overridden. The default implementation simply
compares the provided <code>Mixer.Info</code> to each one in the
array returned by <code>getMixerInfo</code>.</p>
<p>&nbsp;</p>

<!--  footer start -->
<div id="javasefooter">
<div class="hr">
<hr /></div>
<div id="javasecopyright">
<img id="oraclelogofooter" src=
"../../../../images/oraclelogo.gif" alt="Oracle and/or its affiliates"
border="0" width="100" height="29" name=
"oraclelogofooter" />

<a href="../../../../legal/cpyr.html">Copyright
&#169;</a> 1993, 2018, Oracle and/or its affiliates. All rights
reserved.</div>
<div id="javasecontactus">
<a href=
"http://docs.oracle.com/javase/feedback.html">Contact
Us</a>
</div>
</div>
<!-- footer end -->

<!-- STATIC FOOTER -->

</body>
</html>
