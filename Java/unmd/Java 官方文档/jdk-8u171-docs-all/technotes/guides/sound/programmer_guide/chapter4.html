<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xml:lang=
"en-US">
<head>
<title>Chapter 4: Playing Back Audio</title>
<link rel="stylesheet" type="text/css" href="../../../../technotes/css/guide.css" />
</head>
<body>
<!-- STATIC HEADER -->

<!-- header start -->
<div id="javaseheader">
<div id="javaseheaderlogo">
<img src="../../../../images/javalogo.gif"
alt="Java logo" />
</div>
<div id="javaseheaderindex">

<a href=
"../../../../index.html">Documentation Contents</a>
</div>
<div class="clear"></div>
</div>

<!-- header end -->


<p><small><a href="contents.html">&lt; Contents</a></small></p>
<h1>Chapter 4: Playing Back Audio</h1>
<p><a name="a113597" id="a113597"></a> Playback is sometimes
referred to as <em>presentation</em> or <em>rendering</em>. These
are general terms that are applicable to other kinds of media
besides sound. The essential feature is that a sequence of data is
delivered somewhere for eventual perception by a user. If the data
is time-based, as sound is, it must be delivered at the correct
rate. With sound even more than video, it's important that the rate
of data flow be maintained, because interruptions to sound playback
often produce loud clicks or irritating distortion. The Java Sound
API is designed to help application programs play sounds smoothly
and continuously, even very long sounds.</p>
<p><a name="a113599" id="a113599"></a> The previous chapter
discussed how to obtain a line from the audio system or from a
mixer. This chapter shows how to play sound through a line.</p>
<p><a name="a113601" id="a113601"></a> There are two kinds of line
that you can use for playing sound: a <code>Clip</code> and a
<code>SourceDataLine</code>. These two interfaces were introduced
briefly under "<a href="chapter2.html#a112445">The Line Interface
Hierarchy</a>" in Chapter 2, "<a href="chapter2.html">Overview of
the Sampled Package</a>." The chief difference between the two is
that with a <code>Clip</code> you specify all the sound data at one
time, before playback, whereas with a <code>SourceDataLine</code>
you keep writing new buffers of data continuously during playback.
Although there are many situations in which you could use either a
<code>Clip</code> or a <code>SourceDataLine</code>, the following
criteria help identify which kind of line is better suited for a
particular situation:</p>
<ul>
<li style="list-style: none"><a name="a113603" id=
"a113603"></a></li>
<li>Use a <code>Clip</code> when you have non-real-time sound data
that can be preloaded into memory. <a name="a115889" id=
"a115889"></a>
<p>For example, you might read a short sound file into a clip. If
you want the sound to play back more than once, a <code>Clip</code>
is more convenient than a <code>SourceDataLine</code>, especially
if you want the playback to loop (cycle repeatedly through all or
part of the sound). If you need to start the playback at an
arbitrary position in the sound, the <code>Clip</code> interface
provides a method to do that easily. Finally, playback from a
<code>Clip</code> generally has less latency than buffered playback
from a <code>SourceDataLine</code>. In other words, because the
sound is preloaded into a clip, playback can start immediately
instead of having to wait for the buffer to be filled. <a name=
"a113605" id="a113605"></a></p>
</li>
<li>Use a <code>SourceDataLine</code> for streaming data, such as a
long sound file that won't all fit in memory at once, or a sound
whose data can't be known in advance of playback. <a name="a115858"
id="a115858"></a>
<p>As an example of the latter case, suppose you're monitoring
sound input&mdash;that is, playing sound back as it's being
captured. If you don't have a mixer that can send input audio right
back out an output port, your application program will have to take
the captured data and send it to an audio-output mixer. In this
case, a <code>SourceDataLine</code> is more appropriate than a
<code>Clip</code>. Another example of sound that can't be known in
advance occurs when you synthesize or manipulate the sound data
interactively in response to the user's input. For example, imagine
a game that gives aural feedback by "morphing" from one sound to
another as the user moves the mouse. The dynamic nature of the
sound transformation requires the application program to update the
sound data continuously during playback, instead of supplying it
all before playback starts.</p>
</li>
</ul>
<a name="a113609" id="a113609"></a>
<h2>Using a Clip</h2>
<p><a name="a117625" id="a117625"></a> You obtain a
<code>Clip</code> as described earlier under "<a href=
"chapter3.html#a113154">Getting a Line of a Desired Type</a>" in
Chapter 3, "<a href="chapter3.html">Accessing Audio System
Resources</a>": Construct a <code>DataLine.Info</code> object with
<code>Clip.class</code> for the first argument, and pass this
<code>DataLine.Info</code> as an argument to the
<code>getLine</code> method of <code>AudioSystem</code> or
<code>Mixer</code>.</p>
<a name="a113613" id="a113613"></a>
<h3>Setting Up the Clip for Playback</h3>
<p><a name="a113615" id="a113615"></a> Obtaining a line just means
you've gotten a way to refer to it; <code>getLine</code> doesn't
actually reserve the line for you. Because a mixer might have a
limited number of lines of the desired type available, it can
happen that after you invoke <code>getLine</code> to obtain the
clip, another application program jumps in and grabs the clip
before you're ready to start playback. To actually use the clip,
you need to reserve it for your program's exclusive use by invoking
one of the following <code>Clip</code> methods:</p>
<pre>
   void open(AudioInputStream stream) 
   void open(AudioFormat format, byte[] data, int offset,
   int bufferSize)
</pre>
Despite the <code>bufferSize</code> argument in the second
<code>open</code> method above, <code>Clip</code> (unlike
<code>SourceDataLine</code>) includes no methods for writing new
data to the buffer. The <code>bufferSize</code> argument here just
specifies how much of the byte array to load into the clip. It's
not a buffer into which you can subsequently load more data, as you
can with a <code>SourceDataLine's</code> buffer.
<p><a name="a113623" id="a113623"></a> After opening the clip, you
can specify at what point in the data it should start playback,
using <code>Clip's</code> <code>setFramePosition</code> or
<code>setMicroSecondPosition</code> methods. Otherwise, it will
start at the beginning. You can also configure the playback to
cycle repeatedly, using the <code>setLoopPoints</code> method.</p>
<a name="a113626" id="a113626"></a>
<h3>Starting and Stopping Playback</h3>
<p><a name="a113628" id="a113628"></a> When you're ready to start
playback, simply invoke the <code>start</code> method. To stop or
pause the clip, invoke the <code>stop</code> method, and to resume
playback, invoke <code>start</code> again. The clip remembers the
media position where it stopped playback, so there's no need for
explicit pause and resume methods. If you don't want it to resume
where it left off, you can "rewind" the clip to the beginning (or
to any other position, for that matter) using the frame- or
microsecond-positioning methods mentioned above.</p>
<p><a name="a113630" id="a113630"></a> A <code>Clip's</code> volume
level and activity status (active versus inactive) can be monitored
by invoking the <code>DataLine</code> methods <code>getLevel</code>
and <code>isActive</code>, respectively. An active
<code>Clip</code> is one that is currently playing sound.</p>
<a name="a113634" id="a113634"></a>
<h2>Using a SourceDataLine</h2>
<p><a name="a116360" id="a116360"></a> Obtaining a
<code>SourceDataLine</code> is similar to obtaining a
<code>Clip</code>. See "<a href="chapter3.html#a113154">Getting a
Line of a Desired Type</a>" in Chapter 3, "<a href=
"chapter3.html">Accessing Audio System Resources</a>."</p>
<a name="a116365" id="a116365"></a>
<h3>Setting Up the SourceDataLine for Playback</h3>
<p><a name="a116366" id="a116366"></a> Opening the
<code>SourceDataLine</code> is also similar to opening a
<code>Clip</code>, in that the purpose is once again to reserve the
line. However, you use a different method, inherited from
<code>DataLine</code>:</p>
<pre>
    void open(AudioFormat format) 
</pre>
Notice that when you open a <code>SourceDataLine</code>, you don't
associate any sound data with the line yet, unlike opening a
<code>Clip</code>. Instead, you just specify the format of the
audio data you want to play. The system chooses a default buffer
length.
<p><a name="a113646" id="a113646"></a> You can also stipulate a
certain buffer length in bytes, using this variant:</p>
<p><a name="a113648" id="a113648"></a></p>
<pre>
    <code>void open(AudioFormat format, int bufferSize) </code>
</pre>
For consistency with similar methods, the <code>buffersize</code>
argument is expressed in bytes, but it must correspond to an
integral number of frames.
<p><a name="a113652" id="a113652"></a> How would you select a
buffer size? It depends on your program's needs.</p>
<p><a name="a113654" id="a113654"></a> To start with, shorter
buffer sizes mean less latency. When you send new data, you hear it
sooner. For some application programs, particularly highly
interactive ones, this kind of responsiveness is important. For
example, in a game, the onset of playback might need to be tightly
synchronized with a visual event. Such programs might need a
latency of less than 0.1 second. As another example, a conferencing
application needs to avoid delays in both playback and capture.
However, many application programs can afford a greater delay, up
to a second or more, because it doesn't matter exactly when the
sound starts playing, as long as the delay doesn't confuse or annoy
the user. This might be the case for an application program that
streams a large audio file using one-second buffers. The user
probably won't care if playback takes a second to start, because
the sound itself lasts so long and the experience isn't highly
interactive.</p>
<p><a name="a113656" id="a113656"></a> On the other hand, shorter
buffer sizes also mean a greater risk that you'll fail to write
data fast enough into the buffer. If that happens, the audio data
will contain discontinuities, which will probably be audible as
clicks or breakups in the sound. Shorter buffer sizes also mean
that your program has to work harder to keep the buffers filled,
resulting in more intensive CPU usage. This can slow down the
execution of other threads in your program, not to mention other
programs.</p>
<p><a name="a113658" id="a113658"></a> So an optimal value for the
buffer size is one that minimizes latency just to the degree that's
acceptable for your application program, while keeping it large
enough to reduce the risk of buffer underflow and to avoid
unnecessary consumption of CPU resources. For a program like a
conferencing application, delays are more annoying than
low-fidelity sound, so a small buffer size is preferable. For
streaming music, an initial delay is acceptable, but breakups in
the sound are not. Thus for streaming music a larger buffer
size&mdash;say, a second&mdash;is preferable. (Note that high
sample rates make the buffers larger in terms of the number of
bytes, which are the units for measuring buffer size in the
<code>DataLine</code> API.)</p>
<p><a name="a113660" id="a113660"></a> Instead of using the open
method described above, it's also possible to open a
<code>SourceDataLine</code> using <code>Line's</code>
<code>open()</code> method, without arguments. In this case, the
line is opened with its default audio format and buffer size.
However, you can't change these later. If you want to know the
line's default audio format and buffer size, you can invoke
<code>DataLine's</code> <code>getFormat</code> and
<code>getBufferSize</code> methods, even before the line has ever
been opened.</p>
<a name="a113663" id="a113663"></a>
<h3>Starting and Stopping Playback</h3>
<p><a name="a113665" id="a113665"></a> Once the
<code>SourceDataLine</code> is open, you can start playing sound.
You do this by invoking <code>DataLine's</code> start method, and
then writing data repeatedly to the line's playback buffer.</p>
<p><a name="a113667" id="a113667"></a> The start method permits the
line to begin playing sound as soon as there's any data in its
buffer. You place data in the buffer by the following method:</p>
<pre>
    int write(byte[] b, int offset, int length) 
</pre>
The offset into the array is expressed in bytes, as is the array's
length.
<p><a name="a113673" id="a113673"></a> The line begins sending data
as soon as possible to its mixer. When the mixer itself delivers
the data to its target, the <code>SourceDataLine</code> generates a
<code>START</code> event. (In a typical implementation of the Java
Sound API, the delay between the moment that the source line
delivers data to the mixer and the moment that the mixer delivers
the data to its target is negligible&mdash;that is, much less than
the time of one sample.) This <code>START</code> event gets sent to
the line's listeners, as explained below under "<a href=
"chapter4.html#a113711">Monitoring a Line's Status</a>." The line
is now considered active, so the <code>isActive</code> method of
<code>DataLine</code> will return <code>true</code>. Notice that
all this happens only once the buffer contains data to play, not
necessarily right when the start method is invoked. If you invoked
<code>start</code> on a new <code>SourceDataLine</code> but never
wrote data to the buffer, the line would never be active and a
<code>START</code> event would never be sent. (However, in this
case, the <code>isRunning</code> method of <code>DataLine</code>
would return <code>true</code>.)</p>
<p><a name="a113675" id="a113675"></a> So how do you know how much
data to write to the buffer, and when to send the second batch of
data? Fortunately, you don't need to time the second invocation of
write to synchronize with the end of the first buffer! Instead, you
can take advantage of the <code>write</code> method's blocking
behavior:</p>
<ul>
<li style="list-style: none"><a name="a113676" id=
"a113676"></a></li>
<li>The method returns as soon as the data has been written to the
buffer. It doesn't wait until all the data in the buffer has
finished playing. (If it did, you might not have time to write the
next buffer without creating a discontinuity in the audio.)
<a name="a113677" id="a113677"></a></li>
<li>It's all right to try to write more data than the buffer will
hold. In this case, the method blocks (doesn't return) until all
the data you requested has actually been placed in the buffer. In
other words, one buffer's worth of your data at a time will be
written to the buffer and played, until the remaining data all fits
in the buffer, at which point the method returns. Whether or not
the method blocks, it returns as soon as the last buffer's worth of
data from this invocation can be written. Again, this means that
your code will in all likelihood regain control before playback of
the last buffer's worth of data has finished. <a name="a113678" id=
"a113678"></a></li>
<li>While in many contexts it is fine to write more data than the
buffer will hold, if you want to be certain that the next write
issued does not block, you can limit the number of bytes you write
to the number that <code>DataLine's</code> <code>available</code>
method returns.
<p><a name="a113680" id="a113680"></a></p>
</li>
</ul>
Here's an example of iterating through chunks of data that are read
from a stream, writing one chunk at a time to the
<code>SourceDataLine</code> for playback:
<pre>
// read chunks from a stream and write them to a source data 
line 
line.start();
while (total &lt; totalToRead &amp;&amp; !stopped)}
    numBytesRead = stream.read(myData, 0, numBytesToRead);
    if (numBytesRead == -1) break;
    total += numBytesRead; 
    line.write(myData, 0, numBytesRead);

}
</pre>
If you don't want the <code>write</code> method to block, you can
first invoke the <code>available</code> method (inside the loop) to
find out how many bytes can be written without blocking, and then
limit the <code>numBytesToRead</code> variable to this number,
before reading from the stream. In the example given, though,
blocking won't matter much, since the write method is invoked
inside a loop that won't complete until the last buffer is written
in the final loop iteration. Whether or not you use the blocking
technique, you'll probably want to invoke this playback loop in a
separate thread from the rest of the application program, so that
your program doesn't appear to freeze when playing a long sound. On
each iteration of the loop, you can test whether the user has
requested playback to stop. Such a request needs to set the
<code>stopped</code> boolean, used in the code above, to
<code>true</code>.
<p><a name="a113696" id="a113696"></a> Since <code>write</code>
returns before all the data has finished playing, how do you learn
when the playback has actually completed? One way is to invoke the
<code>drain</code> method of <code>DataLine</code> after writing
the last buffer's worth of data. This method blocks until all the
data has been played. When control returns to your program, you can
free up the line, if desired, without fear of prematurely cutting
off the playback of any audio samples:</p>
<pre>
line.write(b, offset, numBytesToWrite); 
//this is the final invocation of write
line.drain();
line.stop();
line.close();
line = null;
</pre>
You can intentionally stop playback prematurely, of course. For
example, the application program might provide the user with a Stop
button. Invoke <code>DataLine's stop</code> method to stop playback
immediately, even in the middle of a buffer. This leaves any
unplayed data in the buffer, so that if you subsequently invoke
<code>start</code>, the playback resumes where it left off. If
that's not what you want to happen, you can discard the data left
in the buffer by invoking <code>flush</code>.
<p><a name="a113708" id="a113708"></a> A
<code>SourceDataLine</code> generates a <code>STOP</code> event
whenever the flow of data has been stopped, whether this stoppage
was initiated by the drain method, the stop method, or the flush
method, or because the end of a playback buffer was reached before
the application program invoked <code>write</code> again to provide
new data. A <code>STOP</code> event doesn't necessarily mean that
the <code>stop</code> method was invoked, and it doesn't
necessarily mean that a subsequent invocation of
<code>isRunning</code> will return <code>false</code>. It does,
however, mean that <code>isActive</code> will return
<code>false</code>. (When the <code>start</code> method has been
invoked, the <code>isRunning</code> method will return
<code>true</code>, even if a <code>STOP</code> event is generated,
and it will begin to return <code>false</code> only once the
<code>stop</code> method is invoked.) It's important to realize
that <code>START</code> and <code>STOP</code> events correspond to
<code>isActive</code>, not to <code>isRunning</code>.</p>
<a name="a113711" id="a113711"></a>
<h2>Monitoring a Line's Status</h2>
<p><a name="a113713" id="a113713"></a> Once you have started a
sound playing, how do you find when it's finished? We saw one
solution above&mdash;invoking the <code>drain</code> method after
writing the last buffer of data&mdash;but that approach is
applicable only to a <code>SourceDataLine</code>. Another approach,
which works for both <code>SourceDataLines</code> and
<code>Clips</code>, is to register to receive notifications from
the line whenever the line changes its state. These notifications
are generated in the form of <code>LineEvent</code> objects, of
which there are four types: <code>OPEN</code>, <code>CLOSE</code>,
<code>START</code>, and <code>STOP</code>.</p>
<p><a name="a113715" id="a113715"></a> Any object in your program
that implements the <code>LineListener</code> interface can
register to receive such notifications. To implement the
<code>LineListener</code> interface, the object simply needs an
update method that takes a <code>LineEvent</code> argument. To
register this object as one of the line's listeners, you invoke the
following <code>Line</code> method:</p>
<p><a name="a113717" id="a113717"></a></p>
<code>public void addLineListener(LineListener listener)</code>
<p>Whenever the line opens, closes, starts, or stops, it sends an
<code>update</code> message to all its listeners. Your object can
query the <code>LineEvent</code> that it receives. First you might
invoke <code>LineEvent.getLine</code> to make sure the line that
stopped is the one you care about. In the case we're discussing
here, you want to know if the sound is finished, so you see whether
the <code>LineEvent</code> is of type <code>STOP</code>. If it is,
you might check the sound's current position, which is also stored
in the <code>LineEvent</code> object, and compare it to the sound's
length (if known) to see whether it reached the end and wasn't
stopped by some other means (such as the user's clicking a Stop
button, although you'd probably be able to determine that cause
elsewhere in your code).</p>
<p><a name="a113721" id="a113721"></a> Along the same lines, if you
need to know when the line is opened, closed, or started, you use
the same mechanism. <code>LineEvents</code> are generated by
different kinds of lines, not just <code>Clips</code> and
<code>SourceDataLines</code>. However, in the case of a
<code>Port</code> you can't count on getting an event to learn
about a line's open or closed state. For example, a
<code>Port</code> might be initially open when it's created, so you
don't invoke the <code>open</code> method and the <code>Port</code>
doesn't ever generate an <code>OPEN</code> event. (See "<a href=
"chapter3.html#a113216">Selecting Input and Output Ports</a>" in
Chapter 3, "<a href="chapter3.html">Accessing Audio System
Resources</a>.")</p>
<a name="a113725" id="a113725"></a>
<h2>Synchronizing Playback on Multiple Lines</h2>
<p><a name="a113727" id="a113727"></a> If you're playing back
multiple tracks of audio simultaneously, you probably want to have
them all start and stop at exactly the same time. Some mixers
facilitate this behavior with their <code>synchronize</code>
method, which lets you apply operations such as <code>open</code>,
<code>close</code>, <code>start</code>, and <code>stop</code> to a
group of data lines using a single command, instead of having to
control each line individually. Furthermore, the degree of accuracy
with which operations are applied to the lines is controllable.</p>
<p><a name="a113729" id="a113729"></a> To find out whether a
particular mixer offers this feature for a specified group of data
lines, invoke the <code>Mixer</code> interface's
<code>isSynchronizationSupported</code> method:</p>
<p><a name="a113731" id="a113731"></a></p>
<pre>
boolean isSynchronizationSupported(Line[] lines, 
  boolean  maintainSync)
</pre>
The first parameter specifies a group of specific data lines, and
the second parameter indicates the accuracy with which
synchronization must be maintained. If the second parameter is
<code>true</code>, the query is asking whether the mixer is capable
of maintaining sample-accurate precision in controlling the
specified lines <em>at all times</em>; otherwise, precise
synchronization is required only during start and stop operations,
not throughout playback. <a name="a113736" id="a113736"></a>
<h2>Processing the Outgoing Audio</h2>
<p><a name="a113738" id="a113738"></a> Some source data lines have
signal-processing controls, such as gain, pan, reverb, and
sample-rate controls. Similar controls, especially gain controls,
might be present on the output ports as well. For more information
on how to determine whether a line has such controls, and how to
use them if it does, see Chapter 6, "<a href=
"chapter6.html">Processing Audio with Controls</a>."</p>
<p>&nbsp;</p>

<!--  footer start -->
<div id="javasefooter">
<div class="hr">
<hr /></div>
<div id="javasecopyright">
<img id="oraclelogofooter" src=
"../../../../images/oraclelogo.gif" alt="Oracle and/or its affiliates"
border="0" width="100" height="29" name=
"oraclelogofooter" />

<a href="../../../../legal/cpyr.html">Copyright
&#169;</a> 1993, 2018, Oracle and/or its affiliates. All rights
reserved.</div>
<div id="javasecontactus">
<a href=
"http://docs.oracle.com/javase/feedback.html">Contact
Us</a>
</div>
</div>
<!-- footer end -->

<!-- STATIC FOOTER -->

</body>
</html>
