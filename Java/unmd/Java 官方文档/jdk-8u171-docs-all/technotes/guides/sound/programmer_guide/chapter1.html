<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xml:lang=
"en-US">
<head>
<title>Chapter 1: Introduction to the Java Sound API</title>
<link rel="stylesheet" type="text/css" href="../../../../technotes/css/guide.css" />
</head>
<body>
<!-- STATIC HEADER -->

<!-- header start -->
<div id="javaseheader">
<div id="javaseheaderlogo">
<img src="../../../../images/javalogo.gif"
alt="Java logo" />
</div>
<div id="javaseheaderindex">

<a href=
"../../../../index.html">Documentation Contents</a>
</div>
<div class="clear"></div>
</div>

<!-- header end -->


<p><small><a href="contents.html">&lt; Contents</a></small></p>
<h1>Chapter 1: Introduction to the Java Sound API</h1>
<h2><a name="design" id="design"></a>Design Goals</h2>
<p><a name="a111812" id="a111812"></a> The Java Sound API is a
low-level API for effecting and controlling the input and output of
sound media, including both audio and Musical Instrument Digital
Interface (MIDI) data. The Java Sound API provides explicit control
over the capabilities normally required for sound input and output,
in a framework that promotes extensibility and flexibility.</p>
<a name="a111814" id="a111814"></a>
<h3>Who is the Java Sound API For?</h3>
<p><a name="a111816" id="a111816"></a> Because sound is so
fundamental, the Java Sound API fulfills the needs of a wide range
of application developers. Potential application areas include:</p>
<ul>
<li style="list-style: none"><a name="a111817" id=
"a111817"></a></li>
<li>Communication frameworks, such as conferencing and telephony
<a name="a111818" id="a111818"></a></li>
<li>End-user content delivery systems, such as media players and
music using streamed content <a name="a111819" id=
"a111819"></a></li>
<li>Interactive application programs, such as games and Web sites
that use dynamic content <a name="a111820" id="a111820"></a></li>
<li>Content creation and editing <a name="a111821" id=
"a111821"></a></li>
<li>Tools, toolkits, and utilities</li>
</ul>
<a name="a111823" id="a111823"></a>
<h3>How Does the Java Sound API Relate to Other Interfaces?</h3>
<p><a name="a111825" id="a111825"></a> The Java Sound API provides
the lowest level of sound support on the Java platform. It provides
application programs with a great amount of control over sound
operations, and it is extensible. For example, the Java Sound API
supplies mechanisms for installing, accessing, and manipulating
system resources such as audio mixers, MIDI synthesizers, other
audio or MIDI devices, file readers and writers, and sound format
converters. The Java Sound API does not include sophisticated sound
editors or graphical tools, but it provides capabilities upon which
such programs can be built. It emphasizes low-level control beyond
that commonly expected by the end user.</p>
<p><a name="a111827" id="a111827"></a> There are other Java
platform APIs that have sound-related elements. The Java Media
Framework (JMF) is a higher-level API that is currently available
as a Standard Extension to the Java platform. JMF specifies a
unified architecture, messaging protocol, and programming interface
for capturing and playing back time-based media. JMF provides a
simpler solution for basic media-player application programs, and
it enables synchronization between different media types, such as
audio and video. On the other hand, programs that focus on sound
can benefit from the Java Sound API, especially if they require
more advanced features, such as the ability to carefully control
buffered audio playback or directly manipulate a MIDI synthesizer.
Other Java APIs with sound aspects include Java 3D and APIs for
telephony and speech. An implementation of any of these APIs might
use an implementation of the Java Sound API internally, but is not
required to do so.</p>
<a name="a111831" id="a111831"></a>
<h2>Packages</h2>
<p><a name="a111832" id="a111832"></a> The Java Sound API includes
support for both digital audio and MIDI data. These two major
modules of functionality are provided in separate packages:</p>
<ul>
<li style="list-style: none"><a name="a111834" id=
"a111834"></a></li>
<li><code>javax.sound.sampled</code> <a name="a111835" id=
"a111835"></a> This package specifies interfaces for capture,
mixing, and playback of digital (sampled) audio. <a name="a111837"
id="a111837"></a></li>
<li><code>javax.sound.midi</code> <a name="a111838" id=
"a111838"></a> This package provides interfaces for MIDI synthesis,
sequencing, and event transport.
<p><a name="a111840" id="a111840"></a></p>
</li>
</ul>
Two other packages permit service providers (as opposed to
application developers) to create custom software components that
extend the capabilities of an implementation of the Java Sound API:
<a name="a111842" id="a111842"></a>
<ul>
<li><code>javax.sound.sampled.spi</code> <a name="a111843" id=
"a111843"></a></li>
<li><code>javax.sound.midi.spi</code>
<p><a name="a111845" id="a111845"></a></p>
</li>
</ul>
The rest of this chapter briefly discusses the sampled-audio
system, the MIDI system, and the SPI packages. Each of these is
then discussed in detail in a subsequent part of the guide.
<a name="a111847" id="a111847"></a>
<h2>Sampled Audio</h2>
<a name="a111849" id="a111849"></a>
<h3>What Is Sampled Audio?</h3>
<p><a name="a112308" id="a112308"></a> The
<code>javax.sound.sampled</code> package handles digital audio
data, which the Java Sound API refers to as sampled audio.
<em>Samples</em> are successive snapshots of a signal. In the case
of audio, the signal is a sound wave. A microphone converts the
acoustic signal into a corresponding analog electrical signal, and
an analog-to-digital converter transforms that analog signal into a
sampled digital form. The following figure shows a brief moment in
a sound recording.</p>
<i><img src="images/chapter1.anc.gif" alt="A sampled sound wave"
width="268" height="239" /></i> <i>A Sampled Sound Wave</i>
<p><a name="a111861" id="a111861"></a> This graph plots sound
pressure (amplitude) on the vertical axis, and time on the
horizontal axis. The amplitude of the analog sound wave is measured
periodically at a certain rate, resulting in the discrete samples
(the red data points in the figure) that comprise the digital audio
signal. The center horizontal line indicates zero amplitude; points
above the line are positive-valued samples, and points below are
negative. The accuracy of the digital approximation of the analog
signal depends on its resolution in time (the <em>sampling
rate</em>) and its <em>quantization</em>, or resolution in
amplitude (the number of bits used to represent each sample). As a
point of reference, the audio recorded for storage on compact discs
is sampled 44,100 times per second and represented with 16 bits per
sample.</p>
<p><a name="a115938" id="a115938"></a> The term "sampled audio" is
used here slightly loosely. A sound wave could be sampled at
discrete intervals while being left in an analog form. For purposes
of the Java Sound API, however, "sampled audio" is equivalent to
"digital audio."</p>
<p><a name="a115936" id="a115936"></a> Typically, sampled audio on
a computer comes from a sound recording, but the sound could
instead be synthetically generated (for example, to create the
sounds of a touch-tone telephone). The term "sampled audio" refers
to the type of data, not its origin.</p>
<p><a name="a112752" id="a112752"></a> Further information about
the structure of digital audio data is given under "<a href=
"chapter2.html#a112348">What Is Formatted Audio Data?</a>" in
Chapter 2, "<a href="chapter2.html">Overview of the Sampled
Package</a>."</p>
<a name="a112759" id="a112759"></a>
<h3>Audio Configurations</h3>
<p><a name="a111869" id="a111869"></a> The Java Sound API does not
assume a specific audio hardware configuration; it is designed to
allow different sorts of audio components to be installed on a
system and accessed by the API. The Java Sound API supports common
functionality such as input and output from a sound card (for
example, for recording and playback of sound files) as well as
mixing of multiple streams of audio. Here is one example of a
typical audio architecture:</p>
<p><a name="a112280" id="a112280"></a> <img src=
"images/chapter1.anc1.gif" alt=
"The following context describes this graphic" width="413" height=
"251" /></p>
<i>A Typical Audio Architecture</i>
<p><a name="a111874" id="a111874"></a> In this example, a device
such as a sound card has various input and output ports, and mixing
is provided in the software. The mixer might receive data that has
been read from a file, streamed from a network, generated on the
fly by an application program, or produced by a MIDI synthesizer.
(The <code>javax.sound.midi</code> package, discussed next,
supplies a Java language interface for synthesizers.) The mixer
combines all its audio inputs into a single stream, which can be
sent to an output device for rendering.</p>
<a name="a111877" id="a111877"></a>
<h2>MIDI</h2>
<p><a name="a111878" id="a111878"></a> The
<code>javax.sound.midi</code> package contains APIs for
transporting and sequencing MIDI events, and for synthesizing sound
from those events.</p>
<a name="a111880" id="a111880"></a>
<h3>What Is MIDI?</h3>
<p><a name="a112123" id="a112123"></a> Whereas sampled audio is a
direct representation of a sound itself, MIDI data can be thought
of as a recipe for creating a sound, especially a musical sound.
MIDI data, unlike audio data, does not describe sound directly.
Instead, it describes events that affect the sound a synthesizer is
making. MIDI data is analogous to a graphical user interface's
keyboard and mouse events. In the case of MIDI, the events can be
thought of as actions upon a musical keyboard, along with actions
on various pedals, sliders, switches, and knobs on that musical
instrument. These events need not actually originate with a
hardware musical instrument; they can be simulated in software, and
they can be stored in MIDI files. A program that can create, edit,
and perform these files is called a sequencer. Many computer sound
cards include MIDI-controllable music synthesizer chips to which
sequencers can send their MIDI events. Synthesizers can also be
implemented entirely in software. The synthesizers interpret the
MIDI events that they receive and produce audio output. Usually the
sound synthesized from MIDI data is musical sound (as opposed to
speech, for example). MIDI synthesizers are also capable of
generating various kinds of sound effects.</p>
<p><a name="a111884" id="a111884"></a> Some sound cards include
MIDI input and output ports to which external MIDI hardware devices
(such as keyboard synthesizers or other instruments) can be
connected. From a MIDI input port, an application program can
receive events generated by an external MIDI-equipped musical
instrument. The program might play the musical performance using
the computer's internal synthesizer, save it to disk as a MIDI
file, or render it into musical notation. A program might use a
MIDI output port to play an external instrument, or to control
other external devices such as recording equipment.</p>
<p><a name="a112482" id="a112482"></a> More information about MIDI
data is given in Chapter 8, "<a href="chapter8.html">Overview of
the MIDI Package</a>," particularly in the section "A MIDI
Refresher: Wires and Files."</p>
<a name="a112483" id="a112483"></a>
<h3>MIDI Configurations</h3>
<p><a name="a112765" id="a112765"></a> The diagram below
illustrates the functional relationships between the major
components in a possible MIDI configuration based on the Java Sound
API. (As with audio, the Java Sound API permits a variety of MIDI
software devices to be installed and interconnected. The system
shown here is one potential scenario.) The flow of data between
components is indicated by arrows. The data can be in a standard
file format, or (as indicated by the key in the lower right corner
of the diagram), it can be audio, raw MIDI bytes, or time-tagged
MIDI messages.</p>
<p><a name="a112766" id="a112766"></a> <img src=
"images/chapter1.anc2.gif" alt=
"The following context describes this graphic" width="520" height=
"360" /></p>
<i>A Possible MIDI Configuration</i>
<p><a name="a111896" id="a111896"></a> In this example, the
application program prepares a musical performance by loading a
musical score that's stored as a standard MIDI file on a disk (left
side of the diagram). Standard MIDI files contain tracks, each of
which is a list of time-tagged MIDI events. Most of the events
represent musical notes (pitches and rhythms). This MIDI file is
read and then "performed" by a software sequencer. A sequencer
performs its music by sending MIDI messages to some other device,
such as an internal or external synthesizer. The synthesizer itself
may read a soundbank file containing instructions for emulating the
sounds of certain musical instruments. If not, the synthesizer will
play the notes stored in the MIDI file using whatever instrument
sounds are already loaded into the synthesizer.</p>
<p><a name="a111898" id="a111898"></a> As illustrated, the MIDI
events must be translated into raw (non-time-tagged) MIDI before
being sent through a MIDI output port to an external synthesizer.
Similarly, raw MIDI data coming into the computer from an external
MIDI source (a keyboard instrument, in the diagram) is translated
into time-tagged MIDI messages that can control a synthesizer, or
that a sequencer can store for later use. All these aspects of MIDI
data flow are explained in detail in the subsequent chapters on
MIDI (see Part II of this guide).</p>
<a name="a111901" id="a111901"></a>
<h2>Service Provider Interfaces</h2>
<p><a name="a111902" id="a111902"></a> The
<code>javax.sound.sampled.spi</code> and
<code>javax.sound.midi.spi</code> packages contain APIs that let
software developers create new audio or MIDI resources that can be
provided separately to the user and "plugged in" to an existing
implementation of the Java Sound API. Here are some examples of
services (resources) that can be added in this way:</p>
<ul>
<li style="list-style: none"><a name="a111903" id=
"a111903"></a></li>
<li>An audio mixer <a name="a112110" id="a112110"></a></li>
<li>A MIDI synthesizer <a name="a111906" id="a111906"></a></li>
<li>A file parser that can read or write a new type of audio or
MIDI file <a name="a111907" id="a111907"></a></li>
<li>A converter that translates between different sound data
formats
<p><a name="a111910" id="a111910"></a></p>
</li>
</ul>
In some cases, services are software interfaces to the capabilities
of hardware devices, such as sound cards, and the service provider
might be the same as the vendor of the hardware. In other cases,
the services exist purely in software. For example, a synthesizer
or a mixer could be an interface to a chip on a sound card, or it
could be implemented without any hardware support at all.
<p><a name="a111912" id="a111912"></a> An implementation of the
Java Sound API contains a basic set of services, but the service
provider interface (SPI) packages allow third parties to create new
services. These third-party services are integrated into the system
in the same way as the built-in services. The
<code>AudioSystem</code> class in the <code>sampled</code> package
and the <code>MidiSystem</code> class in the <code>midi</code>
package act as coordinators that let application programs access
the services explicitly or implicitly. Often the existence of a
service is completely transparent to an application program that
uses it. The service-provider mechanism benefits users of
application programs based on the Java Sound API, because new sound
features can be added to a program without requiring a new release
of the JDK or runtime environment, and, in many cases, without
even requiring a new release of the application program itself.</p>

<!--  footer start -->
<div id="javasefooter">
<div class="hr">
<hr /></div>
<div id="javasecopyright">
<img id="oraclelogofooter" src=
"../../../../images/oraclelogo.gif" alt="Oracle and/or its affiliates"
border="0" width="100" height="29" name=
"oraclelogofooter" />

<a href="../../../../legal/cpyr.html">Copyright
&#169;</a> 1993, 2018, Oracle and/or its affiliates. All rights
reserved.</div>
<div id="javasecontactus">
<a href=
"http://docs.oracle.com/javase/feedback.html">Contact
Us</a>
</div>
</div>
<!-- footer end -->

<!-- STATIC FOOTER -->

</body>
</html>
